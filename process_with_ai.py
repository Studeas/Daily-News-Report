import json
import os
from datetime import datetime
from typing import List, Dict, Optional
import time
import hashlib

# å¯¼å…¥é…ç½®å’ŒAIå®¢æˆ·ç«¯
from config import config, get_config, is_available, set_provider
from ai_client import AIClient

# é…ç½®
PROMPT_TEMPLATE_FILE = os.getenv('PROMPT_TEMPLATE_FILE', 'prompt_template.txt')
DATA_DIR = 'data'
REPORT_DIR = 'report'

# ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–AIæä¾›å•†
AI_PROVIDER = os.getenv('AI_PROVIDER', 'gemini').lower()

def load_prompt_template() -> str:
    """åŠ è½½promptæ¨¡æ¿æ–‡ä»¶"""
    try:
        if os.path.exists(PROMPT_TEMPLATE_FILE):
            with open(PROMPT_TEMPLATE_FILE, 'r', encoding='utf-8') as f:
                print("æˆåŠŸåŠ è½½ prompt")
                return f.read().strip()
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤æ¨¡æ¿
            print(f"âš ï¸  Promptæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {PROMPT_TEMPLATE_FILE}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
            return """è¯·ä½ å°†ä»¥ä¸‹æ–°é—»ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚"""
    except Exception as e:
        print(f"âš ï¸  åŠ è½½promptæ¨¡æ¿å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
        return """è¯·ä½ å°†ä»¥ä¸‹æ–°é—»ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚"""

def process_article_with_ai(ai_client: AIClient, article: Dict) -> Optional[Dict]:
    """
    ä½¿ç”¨AIå¤„ç†å•ç¯‡æ–‡ç« ï¼š
    1. è¿‡æ»¤ä½è´¨é‡æˆ–ä¸ç›¸å…³æ–‡ç« 
    2. æå–å…³é”®ä¿¡æ¯
    3. ç¿»è¯‘ä¸ºä¸­æ–‡
    """
    if not ai_client:
        return None
    
    # å‡†å¤‡æ–‡ç« å†…å®¹
    title = article.get('title', '')
    description = article.get('description', '')
    maintext = article.get('maintext', '')
    authors = article.get('authors', [])
    date_publish = article.get('date_publish', '')
    source = article.get('source_domain', '')
    
    # å¦‚æœæ­£æ–‡å¤ªçŸ­ï¼Œå¯èƒ½ä¸æ˜¯å®Œæ•´æ–‡ç« 
    if not maintext or len(maintext) < 100:
        return None
    
    # é™åˆ¶æ­£æ–‡é•¿åº¦ï¼ˆé¿å…tokené™åˆ¶ï¼‰
    maintext_preview = maintext[:3000] if len(maintext) > 3000 else maintext
    if len(maintext) > 3000:
        maintext_preview += "\n\n[æ–‡ç« å†…å®¹è¾ƒé•¿ï¼Œå·²æˆªæ–­]"
    
    # åŠ è½½å¹¶æ ¼å¼åŒ–promptæ¨¡æ¿
    prompt_template = load_prompt_template()
    prompt = prompt_template.format(
        title=title,
        description=description,
        authors=', '.join(authors) if authors else 'æœªçŸ¥',
        date_publish=date_publish,
        source=source,
        maintext_preview=maintext_preview
    )

    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„AIå®¢æˆ·ç«¯æ¥å£
        response = ai_client.generate_content(prompt)
        
        # æ£€æŸ¥é”™è¯¯
        if 'error' in response:
            error = response['error']
            if 'å®‰å…¨è¿‡æ»¤å™¨' in error or 'SAFETY' in str(response.get('finish_reason', '')):
                print(f"  âš ï¸  å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢")
                # è¿”å›åŸºç¡€æ•°æ®
                return {
                    "original": {
                        "title": title,
                        "description": description,
                        "maintext": maintext,
                        "authors": authors,
                        "date_publish": date_publish,
                        "source_domain": source,
                        "url": article.get('url', ''),
                        "homepage_source": article.get('homepage_source', ''),
                    },
                    "processed": {
                        "is_valid": True,
                        "category": "å…¶ä»–",
                        "key_points": [],
                        "title_zh": "",
                        "description_zh": "",
                        "summary_zh": "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œæ— æ³•è¿›è¡ŒAIå¤„ç†",
                        "maintext_zh": "",
                    },
                    "metadata": {
                        "processed_at": datetime.now().isoformat(),
                        "source": f"blocked_by_safety_filter_{ai_client.provider}"
                    }
                }
            else:
                print(f"  âš ï¸  AIå¤„ç†å¤±è´¥: {error}")
                return None
        
        result_text = response.get('text', '')
        if not result_text:
            print(f"  âš ï¸  å“åº”ä¸­æ²¡æœ‰æ–‡æœ¬å†…å®¹")
            return None
        
        # å°è¯•æå–JSONï¼ˆå¯èƒ½è¿”å›markdownæ ¼å¼çš„ä»£ç å—ï¼‰
        if '```json' in result_text:
            result_text = result_text.split('```json')[1].split('```')[0].strip()
        elif '```' in result_text:
            parts = result_text.split('```')
            for i, part in enumerate(parts):
                if i % 2 == 1:  # ä»£ç å—å†…å®¹
                    try:
                        json.loads(part.strip())
                        result_text = part.strip()
                        break
                    except:
                        continue
        
        # å¦‚æœä»ç„¶åŒ…å«JSONå¯¹è±¡ï¼Œå°è¯•æå–
        if '{' in result_text and '}' in result_text:
            start = result_text.find('{')
            end = result_text.rfind('}') + 1
            result_text = result_text[start:end]
        
        # è§£æJSON
        ai_result = json.loads(result_text)
        
        # åˆå¹¶åŸå§‹æ•°æ®å’ŒAIå¤„ç†ç»“æœ
        is_valid = ai_result.get('is_valid', False)
        
        # å¦‚æœæ–‡ç« æ— æ•ˆï¼ˆè¢«è¿‡æ»¤ï¼‰ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µä¸ºç©º
        if not is_valid:
            processed_article = {
                "original": {
                    "title": title,
                    "description": description,
                    "maintext": maintext,
                    "authors": authors,
                    "date_publish": date_publish,
                    "source_domain": source,
                    "url": article.get('url', ''),
                    "homepage_source": article.get('homepage_source', ''),
                },
                "processed": {
                    "is_valid": False,
                    "category": "",  # æ— æ•ˆæ–‡ç« ï¼Œåˆ†ç±»ä¸ºç©º
                    "key_points": [],  # æ— æ•ˆæ–‡ç« ï¼Œå…³é”®ç‚¹ä¸ºç©º
                    "title_zh": "",  # æ— æ•ˆæ–‡ç« ï¼Œä¸ç¿»è¯‘
                    "description_zh": "",  # æ— æ•ˆæ–‡ç« ï¼Œä¸ç¿»è¯‘
                    "summary_zh": "",  # æ— æ•ˆæ–‡ç« ï¼Œä¸ç¿»è¯‘
                    "maintext_zh": "",  # æ— æ•ˆæ–‡ç« ï¼Œä¸ç¿»è¯‘
                },
                "metadata": {
                    "processed_at": datetime.now().isoformat(),
                    "source": f"{ai_client.provider}-{ai_client.model_name}",
                    "filtered_reason": "éä¸¥è‚ƒæ–°é—»ï¼ˆèŠ±è¾¹/å¨±ä¹/ä½“è‚²/å…»ç”Ÿä¿å¥ç­‰ï¼‰"
                }
            }
        else:
            # æœ‰æ•ˆæ–‡ç« ï¼Œæ­£å¸¸å¤„ç†
            processed_article = {
                "original": {
                    "title": title,
                    "description": description,
                    "maintext": maintext,
                    "authors": authors,
                    "date_publish": date_publish,
                    "source_domain": source,
                    "url": article.get('url', ''),
                    "homepage_source": article.get('homepage_source', ''),
                },
                "processed": {
                    "is_valid": True,
                    "category": ai_result.get('category', 'å…¶ä»–æ— å…³æ–°é—»'),
                    "key_points": ai_result.get('key_points', []),
                    "title_zh": ai_result.get('title_zh', ''),
                    "description_zh": ai_result.get('description_zh', ''),
                    "summary_zh": ai_result.get('summary_zh', ''),
                    "maintext_zh": ai_result.get('maintext_zh', ''),
                },
                "metadata": {
                    "processed_at": datetime.now().isoformat(),
                    "source": f"{ai_client.provider}-{ai_client.model_name}"
                }
            }
        
        return processed_article
        
    except json.JSONDecodeError as e:
        print(f"  âš ï¸  JSONè§£æå¤±è´¥: {e}")
        if 'result_text' in locals():
            print(f"  å“åº”å†…å®¹: {result_text[:200]}")
        return None
    except Exception as e:
        print(f"  âš ï¸  AIå¤„ç†å¤±è´¥: {e}")
        return None

def find_latest_articles_file() -> Optional[str]:
    """ä»dataæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æœ€æ–°çš„æ–‡ç« JSONæ–‡ä»¶"""
    if not os.path.exists(DATA_DIR):
        print(f"âŒ æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {DATA_DIR}")
        return None
    
    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    json_files = []
    for filename in os.listdir(DATA_DIR):
        if filename.endswith('.json'):
            filepath = os.path.join(DATA_DIR, filename)
            if os.path.isfile(filepath):
                mtime = os.path.getmtime(filepath)
                json_files.append((mtime, filepath, filename))
    
    if not json_files:
        print(f"âŒ åœ¨ {DATA_DIR} æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    json_files.sort(reverse=True)
    latest_file = json_files[0][1]
    print(f"âœ“ æ‰¾åˆ°æœ€æ–°æ–‡ç« æ–‡ä»¶: {json_files[0][2]}")
    return latest_file

def get_article_id(article: Dict) -> str:
    """ç”Ÿæˆæ–‡ç« å”¯ä¸€IDï¼ˆåŸºäºURLï¼‰"""
    url = article.get('url', '')
    if url:
        return hashlib.md5(url.encode()).hexdigest()
    # å¦‚æœæ²¡æœ‰URLï¼Œä½¿ç”¨æ ‡é¢˜+æ¥æºçš„ç»„åˆ
    title = article.get('title', '')
    source = article.get('source_domain', '')
    return hashlib.md5(f"{title}_{source}".encode()).hexdigest()

def load_processed_cache(cache_file: str) -> Dict[str, Dict]:
    """åŠ è½½å·²å¤„ç†çš„æ–‡ç« ç¼“å­˜"""
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                print(f"  âœ“ åŠ è½½ç¼“å­˜: {len(cache_data)} ç¯‡å·²å¤„ç†æ–‡ç« ")
                return cache_data
        except Exception as e:
            print(f"  âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return {}
    return {}

def save_processed_cache(cache_file: str, processed_dict: Dict[str, Dict]):
    """ä¿å­˜å·²å¤„ç†çš„æ–‡ç« ç¼“å­˜"""
    try:
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
        temp_file = cache_file + '.tmp'
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(processed_dict, f, ensure_ascii=False, indent=2)
        os.replace(temp_file, cache_file)
    except Exception as e:
        print(f"  âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

def save_intermediate_results(processed_articles: List[Dict], report_dir: str):
    """ä¿å­˜ä¸­é—´ç»“æœ"""
    try:
        intermediate_file = os.path.join(report_dir, 'report_intermediate.json')
        report = generate_report(processed_articles)
        with open(intermediate_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"  âš ï¸  ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")

def load_articles() -> List[Dict]:
    """åŠ è½½æ–‡ç« æ•°æ®ï¼ˆä»dataæ–‡ä»¶å¤¹ä¸­åŠ è½½æœ€æ–°çš„æ–‡ä»¶ï¼‰"""
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„æ–‡ä»¶
    articles_file = os.getenv('ARTICLES_FILE')
    
    if articles_file:
        # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        if not os.path.isabs(articles_file):
            articles_file = os.path.join(DATA_DIR, articles_file) if not os.path.exists(articles_file) else articles_file
    else:
        # å¦åˆ™æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶
        articles_file = find_latest_articles_file()
    
    if not articles_file:
        return []
    
    try:
        with open(articles_file, 'r', encoding='utf-8') as f:
            articles = json.load(f)
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(articles)} ç¯‡æ–‡ç« ")
        return articles
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {articles_file}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        return []

def generate_report(processed_articles: List[Dict]) -> Dict:
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    total = len(processed_articles)
    valid_articles = [a for a in processed_articles if a['processed']['is_valid']]
    invalid_count = total - len(valid_articles)
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    category_stats = {}
    for article in valid_articles:
        category = article['processed']['category']
        category_stats[category] = category_stats.get(category, 0) + 1
    
    # æŒ‰æ¥æºç»Ÿè®¡
    source_stats = {}
    for article in valid_articles:
        source = article['original']['source_domain']
        source_stats[source] = source_stats.get(source, 0) + 1
    
    report = {
        "summary": {
            "total_articles": total,
            "valid_articles": len(valid_articles),
            "invalid_articles": invalid_count,
            "processing_date": datetime.now().isoformat(),
        },
        "statistics": {
            "by_category": category_stats,
            "by_source": source_stats,
        },
        "articles": valid_articles
    }
    
    return report

def generate_markdown_report(report: Dict) -> str:
    """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
    md = []
    
    # æ ‡é¢˜
    md.append("# å°¼æ—¥åˆ©äºšæ–°é—»æ±‡æ€»æŠ¥å‘Š\n")
    md.append(f"**ç”Ÿæˆæ—¶é—´**: {report['summary']['processing_date']}\n")
    
    # æ‘˜è¦
    md.append("## ğŸ“Š æ•°æ®æ‘˜è¦\n")
    md.append(f"- **æ€»æ–‡ç« æ•°**: {report['summary']['total_articles']}")
    md.append(f"- **æœ‰æ•ˆæ–‡ç« **: {report['summary']['valid_articles']}")
    md.append(f"- **æ— æ•ˆæ–‡ç« **: {report['summary']['invalid_articles']}\n")
    
    # åˆ†ç±»ç»Ÿè®¡
    md.append("## ğŸ“ åˆ†ç±»ç»Ÿè®¡\n")
    for category, count in sorted(report['statistics']['by_category'].items(), 
                                  key=lambda x: x[1], reverse=True):
        md.append(f"- **{category}**: {count} ç¯‡")
    md.append("")
    
    # æ¥æºç»Ÿè®¡
    md.append("## ğŸ“° æ¥æºç»Ÿè®¡\n")
    for source, count in sorted(report['statistics']['by_source'].items(), 
                               key=lambda x: x[1], reverse=True):
        md.append(f"- **{source}**: {count} ç¯‡")
    md.append("")
    
    # æ–‡ç« åˆ—è¡¨
    md.append("## ğŸ“„ æ–‡ç« è¯¦æƒ…\n")
    md.append("---\n")
    
    for i, article in enumerate(report['articles'], 1):
        original = article['original']
        processed = article['processed']
        
        md.append(f"### {i}. {processed['title_zh'] or original['title']}\n")
        md.append(f"**åŸæ–‡æ ‡é¢˜**: {original['title']}\n")
        md.append(f"**åˆ†ç±»**: {processed['category']}\n")
        md.append(f"**æ¥æº**: {original['source_domain']}\n")
        md.append(f"**ä½œè€…**: {', '.join(original['authors']) if original['authors'] else 'æœªçŸ¥'}\n")
        md.append(f"**å‘å¸ƒæ—¥æœŸ**: {original['date_publish']}\n")
        md.append(f"**é“¾æ¥**: {original['url']}\n")
        
        if processed['description_zh']:
            md.append(f"\n**æè¿°**:\n{processed['description_zh']}\n")
        
        if processed['key_points']:
            md.append("\n**å…³é”®è¦ç‚¹**:\n")
            for point in processed['key_points']:
                md.append(f"- {point}")
            md.append("")
        
        if processed['summary_zh']:
            md.append(f"\n**æ‘˜è¦**:\n{processed['summary_zh']}\n")
        
        if processed['maintext_zh']:
            md.append("\n**æ­£æ–‡ï¼ˆä¸­æ–‡ï¼‰**:\n")
            md.append(f"{processed['maintext_zh']}\n")
        
        md.append("\n---\n")
    
    return "\n".join(md)

def generate_html_report(report: Dict) -> str:
    """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
    html = []
    
    # HTMLå¤´éƒ¨
    processing_date = report['summary']['processing_date']
    html.append(f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å°¼æ—¥åˆ©äºšæ–°é—»æ±‡æ€»æŠ¥å‘Š</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 30px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }}
        h3 {{
            color: #555;
            margin-top: 25px;
        }}
        .summary {{
            background: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }}
        .summary-item {{
            margin: 10px 0;
            font-size: 16px;
        }}
        .summary-item strong {{
            color: #2980b9;
        }}
        .stats {{
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin: 20px 0;
        }}
        .stat-card {{
            background: #fff;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            min-width: 200px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }}
        .stat-card h4 {{
            margin: 0 0 10px 0;
            color: #7f8c8d;
            font-size: 14px;
        }}
        .stat-card .value {{
            font-size: 24px;
            font-weight: bold;
            color: #2c3e50;
        }}
        .article {{
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
            background: #fafafa;
        }}
        .article-header {{
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 15px;
        }}
        .article-title {{
            font-size: 20px;
            color: #2c3e50;
            margin: 0;
        }}
        .article-meta {{
            color: #7f8c8d;
            font-size: 14px;
            margin: 10px 0;
        }}
        .article-meta span {{
            margin-right: 15px;
        }}
        .key-points {{
            background: #e8f5e9;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }}
        .key-points ul {{
            margin: 0;
            padding-left: 20px;
        }}
        .key-points li {{
            margin: 8px 0;
        }}
        .content {{
            margin: 15px 0;
            line-height: 1.8;
        }}
        .link {{
            color: #3498db;
            text-decoration: none;
        }}
        .link:hover {{
            text-decoration: underline;
        }}
        .category-badge {{
            display: inline-block;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            background: #3498db;
            color: white;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“° å°¼æ—¥åˆ©äºšæ–°é—»æ±‡æ€»æŠ¥å‘Š</h1>
        <div class="summary">
            <div class="summary-item"><strong>ç”Ÿæˆæ—¶é—´</strong>: {processing_date}</div>
        </div>
    """)
    
    # æ•°æ®æ‘˜è¦
    total_articles = report['summary']['total_articles']
    valid_articles = report['summary']['valid_articles']
    invalid_articles = report['summary']['invalid_articles']
    html.append(f"""
        <h2>ğŸ“Š æ•°æ®æ‘˜è¦</h2>
        <div class="stats">
            <div class="stat-card">
                <h4>æ€»æ–‡ç« æ•°</h4>
                <div class="value">{total_articles}</div>
            </div>
            <div class="stat-card">
                <h4>æœ‰æ•ˆæ–‡ç« </h4>
                <div class="value">{valid_articles}</div>
            </div>
            <div class="stat-card">
                <h4>æ— æ•ˆæ–‡ç« </h4>
                <div class="value">{invalid_articles}</div>
            </div>
        </div>
    """)
    
    # åˆ†ç±»ç»Ÿè®¡
    html.append("<h2>ğŸ“ åˆ†ç±»ç»Ÿè®¡</h2>")
    html.append('<div class="stats">')
    for category, count in sorted(report['statistics']['by_category'].items(), 
                                  key=lambda x: x[1], reverse=True):
        html.append(f"""
            <div class="stat-card">
                <h4>{category}</h4>
                <div class="value">{count} ç¯‡</div>
            </div>
        """)
    html.append("</div>")
    
    # æ¥æºç»Ÿè®¡
    html.append("<h2>ğŸ“° æ¥æºç»Ÿè®¡</h2>")
    html.append('<div class="stats">')
    for source, count in sorted(report['statistics']['by_source'].items(), 
                               key=lambda x: x[1], reverse=True):
        html.append(f"""
            <div class="stat-card">
                <h4>{source}</h4>
                <div class="value">{count} ç¯‡</div>
            </div>
        """)
    html.append("</div>")
    
    # æ–‡ç« åˆ—è¡¨
    html.append("<h2>ğŸ“„ æ–‡ç« è¯¦æƒ…</h2>")
    
    for i, article in enumerate(report['articles'], 1):
        original = article['original']
        processed = article['processed']
        
        html.append('<div class="article">')
        html.append('<div class="article-header">')
        html.append(f'<h3 class="article-title">{i}. {processed["title_zh"] or original["title"]}</h3>')
        html.append(f'<span class="category-badge">{processed["category"]}</span>')
        html.append('</div>')
        
        html.append('<div class="article-meta">')
        html.append(f'<span><strong>åŸæ–‡æ ‡é¢˜</strong>: {original["title"]}</span>')
        html.append(f'<span><strong>æ¥æº</strong>: {original["source_domain"]}</span>')
        if original['authors']:
            html.append(f'<span><strong>ä½œè€…</strong>: {", ".join(original["authors"])}</span>')
        if original['date_publish']:
            html.append(f'<span><strong>å‘å¸ƒæ—¥æœŸ</strong>: {original["date_publish"]}</span>')
        html.append('</div>')
        
        if original['url']:
            html.append(f'<p><a href="{original["url"]}" class="link" target="_blank">æŸ¥çœ‹åŸæ–‡</a></p>')
        
        if processed['description_zh']:
            html.append(f'<div class="content"><strong>æè¿°</strong>:<br>{processed["description_zh"]}</div>')
        
        if processed['key_points']:
            html.append('<div class="key-points"><strong>å…³é”®è¦ç‚¹</strong>:<ul>')
            for point in processed['key_points']:
                html.append(f'<li>{point}</li>')
            html.append('</ul></div>')
        
        if processed['summary_zh']:
            html.append(f'<div class="content"><strong>æ‘˜è¦</strong>:<br>{processed["summary_zh"]}</div>')
        
        if processed['maintext_zh']:
            html.append(f'<div class="content"><strong>æ­£æ–‡ï¼ˆä¸­æ–‡ï¼‰</strong>:<br>{processed["maintext_zh"]}</div>')
        
        html.append('</div>')
    
    # HTMLå°¾éƒ¨
    html.append("""
    </div>
</body>
</html>
    """)
    
    return "\n".join(html)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIæ–°é—»å¤„ç†ä¸æŠ¥å‘Šç”Ÿæˆ")
    print("=" * 60)
    
    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    config.print_status()
    
    # è·å–AIæä¾›å•†ï¼ˆä½¿ç”¨å±€éƒ¨å˜é‡é¿å…ä½œç”¨åŸŸé—®é¢˜ï¼‰
    current_provider = AI_PROVIDER
    
    # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
    if not is_available(current_provider):
        print(f"\nâš ï¸  {current_provider} ä¸å¯ç”¨ï¼Œå°è¯•æŸ¥æ‰¾å¯ç”¨çš„æä¾›å•†...")
        available = config.get_available_providers()
        if available:
            current_provider = available[0]
            print(f"âœ“ ä½¿ç”¨ {current_provider} ä½œä¸ºAIæä¾›å•†")
        else:
            print("\nâŒ æ²¡æœ‰å¯ç”¨çš„AIæä¾›å•†")
            print("   è¯·è®¾ç½®ç›¸åº”çš„APIå¯†é’¥ç¯å¢ƒå˜é‡ï¼š")
            print("   - GEMINI_API_KEY (for gemini)")
            print("   - DASHSCOPE_API_KEY (for tongyi)")
            print("   - DEEPSEEK_API_KEY (for deepseek)")
            print("   - OPENAI_API_KEY (for openai)")
            print("   - ANTHROPIC_API_KEY (for claude)")
            print("   - TENCENT_SECRET_ID & TENCENT_SECRET_KEY (for hunyuan)")
            return
    
    try:
        ai_client = AIClient(current_provider)
        print(f"âœ“ AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {ai_client.provider} ({ai_client.model_name})")
    except Exception as e:
        print(f"\nâŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        print("   å°†ä½¿ç”¨åŸºç¡€å¤„ç†æ¨¡å¼ï¼ˆæ— AIåŠŸèƒ½ï¼‰")
        ai_client = None
    
    # åŠ è½½æ–‡ç« 
    print(f"\nğŸ“‚ åŠ è½½æ–‡ç« æ•°æ®...")
    articles = load_articles()
    
    if not articles:
        print("âŒ æ²¡æœ‰å¯å¤„ç†çš„æ–‡ç« ")
        return
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•å’Œç¼“å­˜æ–‡ä»¶è·¯å¾„
    today = datetime.now().strftime("%Y%m%d")
    report_date_dir = os.path.join(REPORT_DIR, today)
    os.makedirs(report_date_dir, exist_ok=True)
    cache_file = os.path.join(report_date_dir, 'processed_cache.json')
    
    # åŠ è½½å·²å¤„ç†çš„æ–‡ç« ç¼“å­˜ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    print(f"\nğŸ“‹ æ£€æŸ¥å·²å¤„ç†ç¼“å­˜...")
    processed_cache = load_processed_cache(cache_file)
    if processed_cache:
        print(f"  âœ“ å‘ç° {len(processed_cache)} ç¯‡å·²å¤„ç†æ–‡ç« ï¼Œå°†è·³è¿‡è¿™äº›æ–‡ç« ")
    
    # å¤„ç†æ–‡ç« 
    print(f"\nğŸ¤– ä½¿ç”¨AIå¤„ç†æ–‡ç« ...")
    processed_articles = []
    save_interval = 5  # æ¯å¤„ç†5ç¯‡æ–‡ç« ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
    skipped_count = 0
    
    try:
        for i, article in enumerate(articles, 1):
            article_id = get_article_id(article)
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            if article_id in processed_cache:
                print(f"\n[{i}/{len(articles)}] â­ï¸  è·³è¿‡ï¼ˆå·²å¤„ç†ï¼‰: {article.get('title', 'æ— æ ‡é¢˜')[:50]}...")
                processed_articles.append(processed_cache[article_id])
                skipped_count += 1
                continue
            
            print(f"\n[{i}/{len(articles)}] å¤„ç†: {article.get('title', 'æ— æ ‡é¢˜')[:50]}...")
            
            if ai_client:
                processed = process_article_with_ai(ai_client, article)
                if processed:
                    processed_articles.append(processed)
                    # ç«‹å³ä¿å­˜åˆ°ç¼“å­˜ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
                    processed_cache[article_id] = processed
                    save_processed_cache(cache_file, processed_cache)
                    
                    # æ¯å¤„ç†Nç¯‡ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
                    new_processed_count = len(processed_articles) - skipped_count
                    if new_processed_count > 0 and new_processed_count % save_interval == 0:
                        print(f"  ğŸ’¾ ä¿å­˜ä¸­é—´ç»“æœï¼ˆå·²å¤„ç† {len(processed_articles)} ç¯‡ï¼Œå…¶ä¸­æ–°å¤„ç† {new_processed_count} ç¯‡ï¼‰...")
                        save_intermediate_results(processed_articles, report_date_dir)
                    
                    if processed['processed']['is_valid']:
                        print(f"  âœ“ æœ‰æ•ˆæ–‡ç«  - åˆ†ç±»: {processed['processed']['category']}")
                    else:
                        print(f"  âœ— æ— æ•ˆæ–‡ç« ï¼ˆå·²è¿‡æ»¤ï¼‰")
                else:
                    print(f"  âš ï¸  å¤„ç†å¤±è´¥")
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä½™é¢ä¸è¶³é”™è¯¯ï¼Œå¦‚æœæ˜¯ï¼Œæç¤ºç”¨æˆ·
                    if i == 1:  # åªåœ¨ç¬¬ä¸€ç¯‡æ–‡ç« å¤±è´¥æ—¶æç¤º
                        print(f"\nğŸ’¡ æç¤º: å¦‚æœçœ‹åˆ°'ä½™é¢ä¸è¶³'é”™è¯¯ï¼Œå¯ä»¥ï¼š")
                        print(f"   1. ä¸ºå½“å‰AIæä¾›å•†å……å€¼")
                        print(f"   2. åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨æä¾›å•†: export AI_PROVIDER='gemini' æˆ– 'tongyi'")
                        print(f"   3. æŸ¥çœ‹å¯ç”¨æä¾›å•†: python -c 'from config import config; config.print_status()'")
                
                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                time.sleep(1)
            else:
                # å¦‚æœæ²¡æœ‰AIæ¨¡å‹ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†
                processed = {
                    "original": {
                        "title": article.get('title', ''),
                        "description": article.get('description', ''),
                        "maintext": article.get('maintext', ''),
                        "authors": article.get('authors', []),
                        "date_publish": article.get('date_publish', ''),
                        "source_domain": article.get('source_domain', ''),
                        "url": article.get('url', ''),
                        "homepage_source": article.get('homepage_source', ''),
                    },
                    "processed": {
                        "is_valid": bool(article.get('maintext')),
                        "category": "å…¶ä»–",
                        "key_points": [],
                        "title_zh": "",
                        "description_zh": "",
                        "summary_zh": "",
                        "maintext_zh": "",
                    },
                    "metadata": {
                        "processed_at": datetime.now().isoformat(),
                        "source": "basic"
                    }
                }
                processed_articles.append(processed)
                processed_cache[article_id] = processed
                save_processed_cache(cache_file, processed_cache)
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å·²å¤„ç†çš„ç»“æœ...")
    except Exception as e:
        print(f"\n\nâŒ å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
        print("ğŸ’¾ å°è¯•ä¿å­˜å·²å¤„ç†çš„ç»“æœ...")
    finally:
        # æ— è®ºæ˜¯å¦å¼‚å¸¸ï¼Œéƒ½ä¿å­˜å·²å¤„ç†çš„ç»“æœ
        if processed_articles:
            print(f"\nğŸ’¾ ä¿å­˜æœ€ç»ˆç»“æœï¼ˆå…± {len(processed_articles)} ç¯‡ï¼Œå…¶ä¸­è·³è¿‡ {skipped_count} ç¯‡ï¼‰...")
            save_intermediate_results(processed_articles, report_date_dir)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆä½¿ç”¨å·²å¤„ç†çš„ç»“æœï¼‰
    if not processed_articles:
        print("\nâš ï¸  æ²¡æœ‰å·²å¤„ç†çš„æ–‡ç« ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return
    
    print(f"\nğŸ“Š ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
    report = generate_report(processed_articles)
    
    # ä¿å­˜JSONæŠ¥å‘Š
    report_json_file = os.path.join(report_date_dir, 'report.json')
    with open(report_json_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"âœ“ JSONæŠ¥å‘Šå·²ä¿å­˜: {report_json_file}")
    
    # ç”Ÿæˆå¹¶ä¿å­˜MarkdownæŠ¥å‘Š
    md_report = generate_markdown_report(report)
    report_md_file = os.path.join(report_date_dir, 'report.md')
    with open(report_md_file, 'w', encoding='utf-8') as f:
        f.write(md_report)
    print(f"âœ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {report_md_file}")
    
    # ç”Ÿæˆå¹¶ä¿å­˜HTMLæŠ¥å‘Š
    html_report = generate_html_report(report)
    report_html_file = os.path.join(report_date_dir, 'report.html')
    with open(report_html_file, 'w', encoding='utf-8') as f:
        f.write(html_report)
    print(f"âœ“ HTMLæŠ¥å‘Šå·²ä¿å­˜: {report_html_file}")
    
    # æ¸…ç†ä¸­é—´ç»“æœæ–‡ä»¶ï¼ˆä¿ç•™æœ€ç»ˆæŠ¥å‘Šï¼‰
    intermediate_file = os.path.join(report_date_dir, 'report_intermediate.json')
    if os.path.exists(intermediate_file):
        try:
            os.remove(intermediate_file)
            print(f"âœ“ å·²æ¸…ç†ä¸­é—´ç»“æœæ–‡ä»¶")
        except:
            pass
    
    # æ‰“å°æ‘˜è¦
    print(f"\n" + "=" * 60)
    print("å¤„ç†å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»æ–‡ç« æ•°: {report['summary']['total_articles']}")
    print(f"æœ‰æ•ˆæ–‡ç« : {report['summary']['valid_articles']}")
    print(f"æ— æ•ˆæ–‡ç« : {report['summary']['invalid_articles']}")
    print(f"\nåˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(report['statistics']['by_category'].items(), 
                                  key=lambda x: x[1], reverse=True):
        print(f"  {category}: {count} ç¯‡")

if __name__ == '__main__':
    main()
