"""
AI API client wrapper
Provides unified interface to call different AI APIs
"""

from typing import Dict, Optional, Any
import json
import re
from config import get_config, is_available

class AIClient:
    """Unified AI client interface"""
    
    def __init__(self, provider: Optional[str] = None):
        """Initialize AI client"""
        self.config = get_config(provider)
        self.provider = self.config['provider']
        self.model_name = self.config.get('default_model')
        
        # Initialize corresponding client
        self.client = self._init_client()
    
    def _init_client(self):
        """Initialize specific AI client"""
        if self.provider == 'gemini':
            return self._init_gemini()
        elif self.provider == 'openai':
            return self._init_openai()
        elif self.provider == 'claude':
            return self._init_claude()
        elif self.provider == 'ollama':
            return self._init_ollama()
        elif self.provider == 'tongyi':
            return self._init_tongyi()
        elif self.provider == 'deepseek':
            return self._init_deepseek()
        elif self.provider == 'hunyuan':
            return self._init_hunyuan()
        elif self.provider == 'zhipu':
            return self._init_zhipu()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}")
    
    def _init_gemini(self):
        """Initialize Gemini client"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.config['api_key'])
            
            # Try different models
            for model_name in self.config['models']:
                try:
                    model = genai.GenerativeModel(model_name)
                    self.model_name = model_name
                    print(f"âœ“ ä½¿ç”¨ Gemini æ¨¡å‹: {model_name}")
                    return model
                except Exception as e:
                    continue
            
            raise Exception("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„Geminiæ¨¡å‹")
        except ImportError:
            raise ImportError("è¯·å®‰è£… google-generativeai: pip install google-generativeai")
    
    def _init_openai(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            import openai
            client = openai.OpenAI(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'gpt-4-turbo-preview')
            print(f"âœ“ ä½¿ç”¨ OpenAI æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _init_claude(self):
        """åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯"""
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'claude-3-sonnet-20240229')
            print(f"âœ“ ä½¿ç”¨ Claude æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… anthropic: pip install anthropic")
    
    def _init_ollama(self):
        """åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯"""
        try:
            import requests
            base_url = self.config.get('base_url', 'http://localhost:11434')
            self.model_name = self.config.get('default_model', 'llama2')
            print(f"âœ“ ä½¿ç”¨ Ollama æ¨¡å‹: {self.model_name} (base_url: {base_url})")
            return {'base_url': base_url}
        except ImportError:
            raise ImportError("è¯·å®‰è£… requests: pip install requests")
    
    def _init_tongyi(self):
        """Initialize Tongyi client (prefer DashScope SDK, fallback to OpenAI compatible interface)"""
        try:
            # Priority: try using DashScope SDK
            try:
                import dashscope
                dashscope.api_key = self.config['api_key']
                self.model_name = self.config.get('default_model', 'qwen-max')
                print(f"âœ“ ä½¿ç”¨ é€šä¹‰åƒé—® æ¨¡å‹: {self.model_name} (DashScope SDK)")
                return {'type': 'dashscope', 'api_key': self.config['api_key']}
            except ImportError:
                # If DashScope SDK is not available, use OpenAI compatible interface
                import openai
                client = openai.OpenAI(
                    api_key=self.config['api_key'],
                    base_url=self.config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
                )
                self.model_name = self.config.get('default_model', 'qwen-max')
                print(f"âœ“ ä½¿ç”¨ é€šä¹‰åƒé—® æ¨¡å‹: {self.model_name} (OpenAIå…¼å®¹æ¥å£)")
                return {'type': 'openai_compat', 'client': client}
        except ImportError:
            raise ImportError("è¯·å®‰è£… dashscope æˆ– openai: pip install dashscope æˆ– pip install openai")
    
    def _init_deepseek(self):
        """Initialize DeepSeek client (using OpenAI compatible interface)"""
        try:
            import openai
            client = openai.OpenAI(
                api_key=self.config['api_key'],
                base_url=self.config.get('base_url', 'https://api.deepseek.com')
            )
            self.model_name = self.config.get('default_model', 'deepseek-chat')
            print(f"âœ“ ä½¿ç”¨ DeepSeek æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _init_hunyuan(self):
        """åˆå§‹åŒ–è…¾è®¯æ··å…ƒå®¢æˆ·ç«¯"""
        try:
            from tencentcloud.common import credential
            from tencentcloud.common.profile.client_profile import ClientProfile
            from tencentcloud.common.profile.http_profile import HttpProfile
            from tencentcloud.hunyuan.v20230901 import hunyuan_client, models
            
            cred = credential.Credential(
                self.config['api_key'],
                self.config.get('secret_key', '')
            )
            
            httpProfile = HttpProfile()
            httpProfile.endpoint = "hunyuan.tencentcloudapi.com"
            
            clientProfile = ClientProfile()
            clientProfile.httpProfile = httpProfile
            clientProfile.language = "zh-CN"
            
            client = hunyuan_client.HunyuanClient(cred, self.config.get('region', 'ap-beijing'), clientProfile)
            self.model_name = self.config.get('default_model', 'hunyuan-lite')
            print(f"âœ“ ä½¿ç”¨ è…¾è®¯æ··å…ƒ æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… tencentcloud-sdk-python: pip install tencentcloud-sdk-python")
    
    def _init_zhipu(self):
        """åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯"""
        try:
            from zai import ZhipuAiClient
            client = ZhipuAiClient(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'glm-4.7')
            print(f"âœ“ ä½¿ç”¨ æ™ºè°±AI æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… zai: pip install zai")
    
    def generate_content(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content (unified interface)"""
        if self.provider == 'gemini':
            return self._generate_gemini(prompt, **kwargs)
        elif self.provider == 'openai':
            return self._generate_openai(prompt, **kwargs)
        elif self.provider == 'claude':
            return self._generate_claude(prompt, **kwargs)
        elif self.provider == 'ollama':
            return self._generate_ollama(prompt, **kwargs)
        elif self.provider == 'tongyi':
            return self._generate_tongyi(prompt, **kwargs)
        elif self.provider == 'deepseek':
            return self._generate_deepseek(prompt, **kwargs)
        elif self.provider == 'hunyuan':
            return self._generate_hunyuan(prompt, **kwargs)
        elif self.provider == 'zhipu':
            return self._generate_zhipu(prompt, **kwargs)
    
    def _generate_gemini(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with Gemini"""
        try:
            response = self.client.generate_content(
                prompt,
                generation_config={
                    'temperature': kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    'max_output_tokens': kwargs.get('max_tokens', self.config.get('max_tokens', 8192)),
                }
            )
            
            # Check response
            if not response.candidates:
                return {'error': 'å“åº”ä¸­æ²¡æœ‰å€™é€‰é¡¹', 'text': None}
            
            candidate = response.candidates[0]
            finish_reason = candidate.finish_reason
            
            # Handle safety filter
            if finish_reason == 1 or str(finish_reason).upper() == "SAFETY":
                return {
                    'error': 'å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢',
                    'finish_reason': 'SAFETY',
                    'text': None,
                    'safety_ratings': getattr(candidate, 'safety_ratings', [])
                }
            
            # Extract text
            try:
                text = response.text.strip()
            except:
                if candidate.content and candidate.content.parts:
                    text = candidate.content.parts[0].text.strip()
                else:
                    return {'error': 'æ— æ³•æå–å“åº”æ–‡æœ¬', 'text': None}
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_openai(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """OpenAIç”Ÿæˆå†…å®¹"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
            )
            
            text = response.choices[0].message.content.strip()
            finish_reason = response.choices[0].finish_reason
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_claude(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Claudeç”Ÿæˆå†…å®¹"""
        try:
            response = self.client.messages.create(
                model=self.model_name,
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            text = response.content[0].text.strip()
            stop_reason = response.stop_reason
            
            return {'text': text, 'finish_reason': stop_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_ollama(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Ollamaç”Ÿæˆå†…å®¹"""
        try:
            import requests
            
            url = f"{self.client['base_url']}/api/generate"
            data = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    "num_predict": kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
                }
            }
            
            response = requests.post(url, json=data, timeout=300)
            response.raise_for_status()
            
            result = response.json()
            text = result.get('response', '').strip()
            
            return {'text': text, 'finish_reason': 'stop'}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_tongyi(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with Tongyi"""
        try:
            # Check client type
            if isinstance(self.client, dict) and self.client.get('type') == 'dashscope':
                # Use DashScope SDK
                import dashscope
                from dashscope import Generation
                
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ]
                
                response = Generation.call(
                    model=self.model_name,
                    messages=messages,
                    temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 2000)),
                )
                
                if response.status_code == 200:
                    text = response.output.choices[0].message.content.strip()
                    return {'text': text, 'finish_reason': 'stop'}
                else:
                    error_msg = f"DashScope APIé”™è¯¯: {response.status_code} - {response.message}"
                    if response.status_code == 401:
                        error_msg += "\næç¤º: APIå¯†é’¥å¯èƒ½æ— æ•ˆã€‚è¯·æ£€æŸ¥ï¼š"
                        error_msg += "\n1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼ˆé€šä¹‰åƒé—®çš„å¯†é’¥é€šå¸¸ä¸ä»¥'sk-'å¼€å¤´ï¼‰"
                        error_msg += "\n2. æ˜¯å¦åœ¨é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°å¼€é€šäº†æœåŠ¡"
                        error_msg += "\n3. è®¿é—® https://bailian.console.aliyun.com/ è·å–æ­£ç¡®çš„APIå¯†é’¥"
                    return {'error': error_msg, 'text': None}
            else:
                # Use OpenAI compatible interface
                client = self.client.get('client') if isinstance(self.client, dict) else self.client
                response = client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 2000)),
                )
                
                text = response.choices[0].message.content.strip()
                finish_reason = response.choices[0].finish_reason
                
                return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve 401 error message
            if '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ é€šä¹‰åƒé—®APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://bailian.console.aliyun.com/"
                error_msg += "\n2. ç™»å½•é˜¿é‡Œäº‘è´¦å·å¹¶å¼€é€šç™¾ç‚¼æœåŠ¡"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥ï¼ˆæ³¨æ„ï¼šå¯†é’¥æ ¼å¼é€šå¸¸ä¸ä»¥'sk-'å¼€å¤´ï¼‰"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY='your-actual-key'"
            return {'error': error_msg, 'text': None}
    
    def _generate_deepseek(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """DeepSeekç”Ÿæˆå†…å®¹ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
            )
            
            text = response.choices[0].message.content.strip()
            finish_reason = response.choices[0].finish_reason
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve error message
            if '402' in error_msg or 'Insufficient Balance' in error_msg or 'ä½™é¢ä¸è¶³' in error_msg:
                error_msg = f"DeepSeekè´¦æˆ·ä½™é¢ä¸è¶³ (402)\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š"
                error_msg += "\n1. è®¿é—® https://platform.deepseek.com/ ç™»å½•è´¦æˆ·"
                error_msg += "\n2. æ£€æŸ¥è´¦æˆ·ä½™é¢å¹¶å……å€¼"
                error_msg += "\n3. æˆ–è€…åˆ‡æ¢åˆ°å…¶ä»–AIæä¾›å•†ï¼ˆå¦‚Geminiã€é€šä¹‰åƒé—®ç­‰ï¼‰"
                error_msg += f"\n   è®¾ç½®ç¯å¢ƒå˜é‡: export AI_PROVIDER='gemini' æˆ–å…¶ä»–å¯ç”¨æä¾›å•†"
            elif '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ DeepSeek APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://platform.deepseek.com/"
                error_msg += "\n2. æ³¨å†Œ/ç™»å½•è´¦æˆ·"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export DEEPSEEK_API_KEY='your-api-key'"
            return {'error': error_msg, 'text': None}
    
    def _generate_hunyuan(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """è…¾è®¯æ··å…ƒç”Ÿæˆå†…å®¹"""
        try:
            from tencentcloud.hunyuan.v20230901 import models
            
            req = models.ChatCompletionsRequest()
            req.Model = self.model_name
            req.Messages = [
                {
                    "Role": "system",
                    "Content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"
                },
                {
                    "Role": "user",
                    "Content": prompt
                }
            ]
            req.Temperature = kwargs.get('temperature', self.config.get('temperature', 0.7))
            req.MaxTokens = kwargs.get('max_tokens', self.config.get('max_tokens', 4096))
            
            resp = self.client.ChatCompletions(req)
            
            if resp.Choices and len(resp.Choices) > 0:
                text = resp.Choices[0].Message.Content.strip()
                finish_reason = getattr(resp.Choices[0], 'FinishReason', 'stop')
                return {'text': text, 'finish_reason': finish_reason}
            else:
                return {'error': 'å“åº”ä¸­æ²¡æœ‰å†…å®¹', 'text': None}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_zhipu(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with ZhipuAI"""
        try:
            # Build request parameters
            request_params = {
                'model': self.model_name,
                'messages': [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                'max_tokens': kwargs.get('max_tokens', self.config.get('max_tokens', 65536)),
                'temperature': kwargs.get('temperature', self.config.get('temperature', 1.0)),
            }
            
            # Control thinking mode explicitly
            # For greeting generation, we don't need thinking mode (it's too verbose)
            thinking_enabled = kwargs.get('thinking_enabled', self.config.get('thinking_enabled', False))
            if thinking_enabled:
                request_params['thinking'] = {
                    "type": "enabled"
                }
            else:
                # Explicitly disable thinking mode for glm-4.7 (which may enable it by default)
                request_params['thinking'] = {
                    "type": "disabled"
                }
            
            response = self.client.chat.completions.create(**request_params)
            
            # Debug: Print full response structure for troubleshooting
            print(f"  ğŸ” [DEBUG] Response type: {type(response)}")
            print(f"  ğŸ” [DEBUG] Response dir: {[attr for attr in dir(response) if not attr.startswith('_')]}")
            
            # Get reply content
            if not hasattr(response, 'choices') or len(response.choices) == 0:
                raise Exception("å“åº”ä¸­æ²¡æœ‰ choices")
            
            choice = response.choices[0]
            print(f"  ğŸ” [DEBUG] Choice type: {type(choice)}")
            print(f"  ğŸ” [DEBUG] Choice dir: {[attr for attr in dir(choice) if not attr.startswith('_')]}")
            
            message = choice.message
            print(f"  ğŸ” [DEBUG] Message type: {type(message)}")
            print(f"  ğŸ” [DEBUG] Message dir: {[attr for attr in dir(message) if not attr.startswith('_')]}")
            
            # ZhipuAI response format may differ, need to adapt
            text = ''
            
            # Try multiple ways to extract content
            # Note: zhipu may put content in 'content' or 'reasoning_content' depending on model
            if hasattr(message, 'content'):
                text = message.content if message.content is not None else ''
                print(f"  ğŸ” [DEBUG] message.content: {repr(text[:100] if text else '')}")
            
            # If content is empty, try reasoning_content (for thinking models)
            # But we need to extract the final answer from reasoning_content, not return the whole thinking process
            if not text and hasattr(message, 'reasoning_content'):
                reasoning = message.reasoning_content if message.reasoning_content is not None else ''
                print(f"  ğŸ” [DEBUG] message.reasoning_content exists (length: {len(reasoning) if reasoning else 0})")
                
                # Try to extract final greeting from reasoning_content
                # Look for patterns like "**é€‰æ‹©ï¼š**" or "æœ€ç»ˆï¼š" or quotes
                # Pattern 1: Look for "**é€‰æ‹©ï¼š**" or "**æœ€ç»ˆï¼š**" followed by quoted text
                patterns = [
                    r'\*\*é€‰æ‹©[ï¼š:]\*\*\s*\*\*([^*]+)\*\*',  # **é€‰æ‹©ï¼š** **é—®å€™è¯­**
                    r'\*\*æœ€ç»ˆ[ï¼š:]\*\*\s*\*\*([^*]+)\*\*',  # **æœ€ç»ˆï¼š** **é—®å€™è¯­**
                    r'é€‰æ‹©[ï¼š:]\s*[â€œ"]([^"â€]+)[â€œ"]',  # é€‰æ‹©ï¼š"é—®å€™è¯­"
                    r'æœ€ç»ˆ[ï¼š:]\s*[â€œ"]([^"â€]+)[â€œ"]',  # æœ€ç»ˆï¼š"é—®å€™è¯­"
                    r'[â€œ"]([^"â€]{5,25})[â€œ"]',  # Any quoted text between 5-25 chars (likely the greeting)
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, reasoning)
                    if matches:
                        # Take the last match (usually the final choice)
                        text = matches[-1].strip()
                        print(f"  ğŸ” [DEBUG] Extracted from reasoning_content: {repr(text)}")
                        break
                
                # If no pattern matched, use reasoning_content as fallback (but it's too verbose)
                if not text and reasoning:
                    # This shouldn't happen, but if it does, we'll use reasoning_content
                    text = reasoning
                    print(f"  âš ï¸  [DEBUG] Could not extract final answer from reasoning_content, using full content")
            
            # Try other possible fields
            if not text and hasattr(message, 'text'):
                text = message.text if message.text is not None else ''
                print(f"  ğŸ” [DEBUG] message.text: {repr(text)}")
            
            # Try to_dict() method (Pydantic model)
            if not text and hasattr(message, 'to_dict'):
                try:
                    msg_dict = message.to_dict()
                    text = msg_dict.get('content', '') or msg_dict.get('reasoning_content', '') or msg_dict.get('text', '')
                    print(f"  ğŸ” [DEBUG] message.to_dict(): {msg_dict}")
                    print(f"  ğŸ” [DEBUG] Extracted from dict: {repr(text)}")
                except Exception as e:
                    print(f"  ğŸ” [DEBUG] to_dict() failed: {e}")
            
            # Try model_dump() method (Pydantic v2)
            if not text and hasattr(message, 'model_dump'):
                try:
                    msg_dict = message.model_dump()
                    text = msg_dict.get('content', '') or msg_dict.get('reasoning_content', '') or msg_dict.get('text', '')
                    print(f"  ğŸ” [DEBUG] message.model_dump(): {msg_dict}")
                    print(f"  ğŸ” [DEBUG] Extracted from model_dump: {repr(text)}")
                except Exception as e:
                    print(f"  ğŸ” [DEBUG] model_dump() failed: {e}")
            
            # Fallback to dict access
            if not text and isinstance(message, dict):
                text = message.get('content', '') or message.get('reasoning_content', '') or message.get('text', '')
                print(f"  ğŸ” [DEBUG] message (dict): {message}")
            
            # Strip whitespace
            text = text.strip() if text else ''
            
            finish_reason = getattr(choice, 'finish_reason', None) or getattr(response.choices[0], 'finish_reason', 'stop')
            print(f"  ğŸ” [DEBUG] finish_reason: {finish_reason}")
            print(f"  ğŸ” [DEBUG] Final text: {repr(text)}")
            
            # If text is still empty, try to access raw response using to_dict or model_dump
            if not text:
                print(f"  ğŸ” [DEBUG] å°è¯•ä»åŸå§‹å“åº”ä¸­æå–...")
                try:
                    # Try to_dict() method
                    if hasattr(response, 'to_dict'):
                        resp_dict = response.to_dict()
                        print(f"  ğŸ” [DEBUG] response.to_dict() keys: {list(resp_dict.keys())}")
                        if 'choices' in resp_dict and resp_dict['choices']:
                            first_choice = resp_dict['choices'][0]
                            if isinstance(first_choice, dict):
                                msg_data = first_choice.get('message', {})
                                text = msg_data.get('content', '') or msg_data.get('reasoning_content', '') or msg_data.get('text', '')
                                print(f"  ğŸ” [DEBUG] ä» to_dict() æå–çš„ text: {repr(text)}")
                                print(f"  ğŸ” [DEBUG] å®Œæ•´çš„ message æ•°æ®: {msg_data}")
                    
                    # Try model_dump() method (Pydantic v2)
                    if not text and hasattr(response, 'model_dump'):
                        resp_dict = response.model_dump()
                        print(f"  ğŸ” [DEBUG] response.model_dump() keys: {list(resp_dict.keys())}")
                        if 'choices' in resp_dict and resp_dict['choices']:
                            first_choice = resp_dict['choices'][0]
                            if isinstance(first_choice, dict):
                                msg_data = first_choice.get('message', {})
                                text = msg_data.get('content', '') or msg_data.get('reasoning_content', '') or msg_data.get('text', '')
                                print(f"  ğŸ” [DEBUG] ä» model_dump() æå–çš„ text: {repr(text)}")
                                print(f"  ğŸ” [DEBUG] å®Œæ•´çš„ message æ•°æ®: {msg_data}")
                    
                    # Try __dict__ as last resort
                    if not text and hasattr(response, '__dict__'):
                        resp_dict = response.__dict__
                        print(f"  ğŸ” [DEBUG] response.__dict__ keys: {list(resp_dict.keys())}")
                        if 'choices' in resp_dict:
                            choices_data = resp_dict['choices']
                            if choices_data and len(choices_data) > 0:
                                first_choice = choices_data[0]
                                if hasattr(first_choice, 'to_dict'):
                                    choice_dict = first_choice.to_dict()
                                    msg_data = choice_dict.get('message', {})
                                    if isinstance(msg_data, dict):
                                        text = msg_data.get('content', '') or msg_data.get('reasoning_content', '')
                                    elif hasattr(msg_data, 'to_dict'):
                                        text = msg_data.to_dict().get('content', '') or msg_data.to_dict().get('reasoning_content', '')
                                    print(f"  ğŸ” [DEBUG] ä» __dict__ æå–çš„ text: {repr(text)}")
                except Exception as e:
                    print(f"  ğŸ” [DEBUG] æå–å¤±è´¥: {e}")
                    import traceback
                    print(f"  ğŸ” [DEBUG] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()[:300]}")
            
            # Final check
            if not text and finish_reason == 'length':
                print(f"  âš ï¸  è­¦å‘Š: finish_reason='length' ä½† text ä¸ºç©º")
                print(f"  âš ï¸  è¿™å¯èƒ½è¡¨ç¤ºå“åº”è¢«æˆªæ–­ï¼Œä½†å†…å®¹æå–å¤±è´¥")
                print(f"  âš ï¸  è¯·æ£€æŸ¥ zhipu SDK çš„å“åº”æ ¼å¼")
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve error message
            if '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ æ™ºè°±AI APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://open.bigmodel.cn/"
                error_msg += "\n2. æ³¨å†Œ/ç™»å½•è´¦æˆ·"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export ZHIPU_API_KEY='your-api-key'"
            elif '402' in error_msg or 'Insufficient Balance' in error_msg or 'ä½™é¢ä¸è¶³' in error_msg:
                error_msg = f"æ™ºè°±AIè´¦æˆ·ä½™é¢ä¸è¶³ (402)\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š"
                error_msg += "\n1. è®¿é—® https://open.bigmodel.cn/ ç™»å½•è´¦æˆ·"
                error_msg += "\n2. æ£€æŸ¥è´¦æˆ·ä½™é¢å¹¶å……å€¼"
                error_msg += "\n3. æˆ–è€…åˆ‡æ¢åˆ°å…¶ä»–AIæä¾›å•†"
            return {'error': error_msg, 'text': None}