"""
AI API client wrapper
Provides unified interface to call different AI APIs
"""

from typing import Dict, Optional, Any
import json
from config import get_config, is_available

class AIClient:
    """Unified AI client interface"""
    
    def __init__(self, provider: Optional[str] = None):
        """Initialize AI client"""
        self.config = get_config(provider)
        self.provider = self.config['provider']
        self.model_name = self.config.get('default_model')
        
        # Initialize corresponding client
        self.client = self._init_client()
    
    def _init_client(self):
        """Initialize specific AI client"""
        if self.provider == 'gemini':
            return self._init_gemini()
        elif self.provider == 'openai':
            return self._init_openai()
        elif self.provider == 'claude':
            return self._init_claude()
        elif self.provider == 'ollama':
            return self._init_ollama()
        elif self.provider == 'tongyi':
            return self._init_tongyi()
        elif self.provider == 'deepseek':
            return self._init_deepseek()
        elif self.provider == 'hunyuan':
            return self._init_hunyuan()
        elif self.provider == 'zhipu':
            return self._init_zhipu()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}")
    
    def _init_gemini(self):
        """Initialize Gemini client"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.config['api_key'])
            
            # Try different models
            for model_name in self.config['models']:
                try:
                    model = genai.GenerativeModel(model_name)
                    self.model_name = model_name
                    print(f"âœ“ ä½¿ç”¨ Gemini æ¨¡å‹: {model_name}")
                    return model
                except Exception as e:
                    continue
            
            raise Exception("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„Geminiæ¨¡å‹")
        except ImportError:
            raise ImportError("è¯·å®‰è£… google-generativeai: pip install google-generativeai")
    
    def _init_openai(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            import openai
            client = openai.OpenAI(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'gpt-4-turbo-preview')
            print(f"âœ“ ä½¿ç”¨ OpenAI æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _init_claude(self):
        """åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯"""
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'claude-3-sonnet-20240229')
            print(f"âœ“ ä½¿ç”¨ Claude æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… anthropic: pip install anthropic")
    
    def _init_ollama(self):
        """åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯"""
        try:
            import requests
            base_url = self.config.get('base_url', 'http://localhost:11434')
            self.model_name = self.config.get('default_model', 'llama2')
            print(f"âœ“ ä½¿ç”¨ Ollama æ¨¡å‹: {self.model_name} (base_url: {base_url})")
            return {'base_url': base_url}
        except ImportError:
            raise ImportError("è¯·å®‰è£… requests: pip install requests")
    
    def _init_tongyi(self):
        """Initialize Tongyi client (prefer DashScope SDK, fallback to OpenAI compatible interface)"""
        try:
            # Priority: try using DashScope SDK
            try:
                import dashscope
                dashscope.api_key = self.config['api_key']
                self.model_name = self.config.get('default_model', 'qwen-max')
                print(f"âœ“ ä½¿ç”¨ é€šä¹‰åƒé—® æ¨¡å‹: {self.model_name} (DashScope SDK)")
                return {'type': 'dashscope', 'api_key': self.config['api_key']}
            except ImportError:
                # If DashScope SDK is not available, use OpenAI compatible interface
                import openai
                client = openai.OpenAI(
                    api_key=self.config['api_key'],
                    base_url=self.config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
                )
                self.model_name = self.config.get('default_model', 'qwen-max')
                print(f"âœ“ ä½¿ç”¨ é€šä¹‰åƒé—® æ¨¡å‹: {self.model_name} (OpenAIå…¼å®¹æ¥å£)")
                return {'type': 'openai_compat', 'client': client}
        except ImportError:
            raise ImportError("è¯·å®‰è£… dashscope æˆ– openai: pip install dashscope æˆ– pip install openai")
    
    def _init_deepseek(self):
        """Initialize DeepSeek client (using OpenAI compatible interface)"""
        try:
            import openai
            client = openai.OpenAI(
                api_key=self.config['api_key'],
                base_url=self.config.get('base_url', 'https://api.deepseek.com')
            )
            self.model_name = self.config.get('default_model', 'deepseek-chat')
            print(f"âœ“ ä½¿ç”¨ DeepSeek æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _init_hunyuan(self):
        """åˆå§‹åŒ–è…¾è®¯æ··å…ƒå®¢æˆ·ç«¯"""
        try:
            from tencentcloud.common import credential
            from tencentcloud.common.profile.client_profile import ClientProfile
            from tencentcloud.common.profile.http_profile import HttpProfile
            from tencentcloud.hunyuan.v20230901 import hunyuan_client, models
            
            cred = credential.Credential(
                self.config['api_key'],
                self.config.get('secret_key', '')
            )
            
            httpProfile = HttpProfile()
            httpProfile.endpoint = "hunyuan.tencentcloudapi.com"
            
            clientProfile = ClientProfile()
            clientProfile.httpProfile = httpProfile
            clientProfile.language = "zh-CN"
            
            client = hunyuan_client.HunyuanClient(cred, self.config.get('region', 'ap-beijing'), clientProfile)
            self.model_name = self.config.get('default_model', 'hunyuan-lite')
            print(f"âœ“ ä½¿ç”¨ è…¾è®¯æ··å…ƒ æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… tencentcloud-sdk-python: pip install tencentcloud-sdk-python")
    
    def _init_zhipu(self):
        """åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯"""
        try:
            from zai import ZhipuAiClient
            client = ZhipuAiClient(api_key=self.config['api_key'])
            self.model_name = self.config.get('default_model', 'glm-4.7')
            print(f"âœ“ ä½¿ç”¨ æ™ºè°±AI æ¨¡å‹: {self.model_name}")
            return client
        except ImportError:
            raise ImportError("è¯·å®‰è£… zai: pip install zai")
    
    def generate_content(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content (unified interface)"""
        if self.provider == 'gemini':
            return self._generate_gemini(prompt, **kwargs)
        elif self.provider == 'openai':
            return self._generate_openai(prompt, **kwargs)
        elif self.provider == 'claude':
            return self._generate_claude(prompt, **kwargs)
        elif self.provider == 'ollama':
            return self._generate_ollama(prompt, **kwargs)
        elif self.provider == 'tongyi':
            return self._generate_tongyi(prompt, **kwargs)
        elif self.provider == 'deepseek':
            return self._generate_deepseek(prompt, **kwargs)
        elif self.provider == 'hunyuan':
            return self._generate_hunyuan(prompt, **kwargs)
        elif self.provider == 'zhipu':
            return self._generate_zhipu(prompt, **kwargs)
    
    def _generate_gemini(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with Gemini"""
        try:
            response = self.client.generate_content(
                prompt,
                generation_config={
                    'temperature': kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    'max_output_tokens': kwargs.get('max_tokens', self.config.get('max_tokens', 8192)),
                }
            )
            
            # Check response
            if not response.candidates:
                return {'error': 'å“åº”ä¸­æ²¡æœ‰å€™é€‰é¡¹', 'text': None}
            
            candidate = response.candidates[0]
            finish_reason = candidate.finish_reason
            
            # Handle safety filter
            if finish_reason == 1 or str(finish_reason).upper() == "SAFETY":
                return {
                    'error': 'å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢',
                    'finish_reason': 'SAFETY',
                    'text': None,
                    'safety_ratings': getattr(candidate, 'safety_ratings', [])
                }
            
            # Extract text
            try:
                text = response.text.strip()
            except:
                if candidate.content and candidate.content.parts:
                    text = candidate.content.parts[0].text.strip()
                else:
                    return {'error': 'æ— æ³•æå–å“åº”æ–‡æœ¬', 'text': None}
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_openai(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """OpenAIç”Ÿæˆå†…å®¹"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
            )
            
            text = response.choices[0].message.content.strip()
            finish_reason = response.choices[0].finish_reason
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_claude(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Claudeç”Ÿæˆå†…å®¹"""
        try:
            response = self.client.messages.create(
                model=self.model_name,
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            text = response.content[0].text.strip()
            stop_reason = response.stop_reason
            
            return {'text': text, 'finish_reason': stop_reason}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_ollama(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Ollamaç”Ÿæˆå†…å®¹"""
        try:
            import requests
            
            url = f"{self.client['base_url']}/api/generate"
            data = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    "num_predict": kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
                }
            }
            
            response = requests.post(url, json=data, timeout=300)
            response.raise_for_status()
            
            result = response.json()
            text = result.get('response', '').strip()
            
            return {'text': text, 'finish_reason': 'stop'}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_tongyi(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with Tongyi"""
        try:
            # Check client type
            if isinstance(self.client, dict) and self.client.get('type') == 'dashscope':
                # Use DashScope SDK
                import dashscope
                from dashscope import Generation
                
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ]
                
                response = Generation.call(
                    model=self.model_name,
                    messages=messages,
                    temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 2000)),
                )
                
                if response.status_code == 200:
                    text = response.output.choices[0].message.content.strip()
                    return {'text': text, 'finish_reason': 'stop'}
                else:
                    error_msg = f"DashScope APIé”™è¯¯: {response.status_code} - {response.message}"
                    if response.status_code == 401:
                        error_msg += "\næç¤º: APIå¯†é’¥å¯èƒ½æ— æ•ˆã€‚è¯·æ£€æŸ¥ï¼š"
                        error_msg += "\n1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼ˆé€šä¹‰åƒé—®çš„å¯†é’¥é€šå¸¸ä¸ä»¥'sk-'å¼€å¤´ï¼‰"
                        error_msg += "\n2. æ˜¯å¦åœ¨é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°å¼€é€šäº†æœåŠ¡"
                        error_msg += "\n3. è®¿é—® https://bailian.console.aliyun.com/ è·å–æ­£ç¡®çš„APIå¯†é’¥"
                    return {'error': error_msg, 'text': None}
            else:
                # Use OpenAI compatible interface
                client = self.client.get('client') if isinstance(self.client, dict) else self.client
                response = client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                    max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 2000)),
                )
                
                text = response.choices[0].message.content.strip()
                finish_reason = response.choices[0].finish_reason
                
                return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve 401 error message
            if '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ é€šä¹‰åƒé—®APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://bailian.console.aliyun.com/"
                error_msg += "\n2. ç™»å½•é˜¿é‡Œäº‘è´¦å·å¹¶å¼€é€šç™¾ç‚¼æœåŠ¡"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥ï¼ˆæ³¨æ„ï¼šå¯†é’¥æ ¼å¼é€šå¸¸ä¸ä»¥'sk-'å¼€å¤´ï¼‰"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY='your-actual-key'"
            return {'error': error_msg, 'text': None}
    
    def _generate_deepseek(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """DeepSeekç”Ÿæˆå†…å®¹ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=kwargs.get('temperature', self.config.get('temperature', 0.7)),
                max_tokens=kwargs.get('max_tokens', self.config.get('max_tokens', 4096)),
            )
            
            text = response.choices[0].message.content.strip()
            finish_reason = response.choices[0].finish_reason
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve error message
            if '402' in error_msg or 'Insufficient Balance' in error_msg or 'ä½™é¢ä¸è¶³' in error_msg:
                error_msg = f"DeepSeekè´¦æˆ·ä½™é¢ä¸è¶³ (402)\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š"
                error_msg += "\n1. è®¿é—® https://platform.deepseek.com/ ç™»å½•è´¦æˆ·"
                error_msg += "\n2. æ£€æŸ¥è´¦æˆ·ä½™é¢å¹¶å……å€¼"
                error_msg += "\n3. æˆ–è€…åˆ‡æ¢åˆ°å…¶ä»–AIæä¾›å•†ï¼ˆå¦‚Geminiã€é€šä¹‰åƒé—®ç­‰ï¼‰"
                error_msg += f"\n   è®¾ç½®ç¯å¢ƒå˜é‡: export AI_PROVIDER='gemini' æˆ–å…¶ä»–å¯ç”¨æä¾›å•†"
            elif '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ DeepSeek APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://platform.deepseek.com/"
                error_msg += "\n2. æ³¨å†Œ/ç™»å½•è´¦æˆ·"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export DEEPSEEK_API_KEY='your-api-key'"
            return {'error': error_msg, 'text': None}
    
    def _generate_hunyuan(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """è…¾è®¯æ··å…ƒç”Ÿæˆå†…å®¹"""
        try:
            from tencentcloud.hunyuan.v20230901 import models
            
            req = models.ChatCompletionsRequest()
            req.Model = self.model_name
            req.Messages = [
                {
                    "Role": "system",
                    "Content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"
                },
                {
                    "Role": "user",
                    "Content": prompt
                }
            ]
            req.Temperature = kwargs.get('temperature', self.config.get('temperature', 0.7))
            req.MaxTokens = kwargs.get('max_tokens', self.config.get('max_tokens', 4096))
            
            resp = self.client.ChatCompletions(req)
            
            if resp.Choices and len(resp.Choices) > 0:
                text = resp.Choices[0].Message.Content.strip()
                finish_reason = getattr(resp.Choices[0], 'FinishReason', 'stop')
                return {'text': text, 'finish_reason': finish_reason}
            else:
                return {'error': 'å“åº”ä¸­æ²¡æœ‰å†…å®¹', 'text': None}
            
        except Exception as e:
            return {'error': str(e), 'text': None}
    
    def _generate_zhipu(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate content with ZhipuAI"""
        try:
            # Build request parameters
            request_params = {
                'model': self.model_name,
                'messages': [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æã€ç¿»è¯‘å’Œæ€»ç»“æ–°é—»æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                'max_tokens': kwargs.get('max_tokens', self.config.get('max_tokens', 65536)),
                'temperature': kwargs.get('temperature', self.config.get('temperature', 1.0)),
            }
            
            # If deep thinking mode is enabled
            if self.config.get('thinking_enabled', False) or kwargs.get('thinking_enabled', False):
                request_params['thinking'] = {
                    "type": "enabled"
                }
            
            response = self.client.chat.completions.create(**request_params)
            
            # Get reply content
            message = response.choices[0].message
            
            # ZhipuAI response format may differ, need to adapt
            if hasattr(message, 'content'):
                text = message.content.strip()
            elif isinstance(message, dict):
                text = message.get('content', '').strip()
            else:
                text = str(message).strip()
            
            finish_reason = getattr(response.choices[0], 'finish_reason', 'stop')
            
            return {'text': text, 'finish_reason': finish_reason}
            
        except Exception as e:
            error_msg = str(e)
            # Improve error message
            if '401' in error_msg or 'invalid_api_key' in error_msg.lower() or 'Incorrect API key' in error_msg:
                error_msg += "\n\nğŸ’¡ æ™ºè°±AI APIå¯†é’¥è·å–æŒ‡å—ï¼š"
                error_msg += "\n1. è®¿é—® https://open.bigmodel.cn/"
                error_msg += "\n2. æ³¨å†Œ/ç™»å½•è´¦æˆ·"
                error_msg += "\n3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥"
                error_msg += "\n4. è®¾ç½®ç¯å¢ƒå˜é‡: export ZHIPU_API_KEY='your-api-key'"
            elif '402' in error_msg or 'Insufficient Balance' in error_msg or 'ä½™é¢ä¸è¶³' in error_msg:
                error_msg = f"æ™ºè°±AIè´¦æˆ·ä½™é¢ä¸è¶³ (402)\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š"
                error_msg += "\n1. è®¿é—® https://open.bigmodel.cn/ ç™»å½•è´¦æˆ·"
                error_msg += "\n2. æ£€æŸ¥è´¦æˆ·ä½™é¢å¹¶å……å€¼"
                error_msg += "\n3. æˆ–è€…åˆ‡æ¢åˆ°å…¶ä»–AIæä¾›å•†"
            return {'error': error_msg, 'text': None}